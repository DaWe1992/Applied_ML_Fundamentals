\input{preamble_theme}

% ====================================================
% ====================================================
% PRESENTATION DATA
% ====================================================
% ====================================================

\title[Machine Learning Introduction]{*** Applied Machine Learning Fundamentals *** Machine Learning Introduction}
\institute{SAP\,SE}
\author{Daniel Wehner}
\date{\today}
\prefix{INTRO}

% ====================================================
% ====================================================
% BEGIN OF DOCUMENT
% ====================================================
% ====================================================

\begin{document}

% Title frame
%______________________________________________________________________
\maketitlepage


% Agenda
%______________________________________________________________________
\begin{frame}{Agenda \today}
	\begin{multicols}{2}
		\tableofcontents
	\end{multicols}
\end{frame}


% Section: General Overview
%______________________________________________________________________
\section{General Overview}
\makedivider{General Overview}

% Why Machine Learning?
\begin{frame}{Why Machine Learning?}{}
	\begin{itemize}
		\item \textit{`We are drowning in information and starving for knowledge.' \\
			\hfill\textbf{-- John Naisbitt}}
		\item \textbf{Era of big data:}
		\begin{itemize}
			\item In 2017 there are about \textbf{1.8 trillion} web-pages on the internet
			\item \textbf{20 hours} of video are uploaded to YouTube every minute
			\item Walmart handles more than \textbf{1 million} transactions per hour and has data bases containing more 
				than \textbf{2.5 peta-bytes} ($2.5 \times 10^15$) of information
		\end{itemize}
		\item \Highlight{No human being can deal with this data avalanche!}
	\end{itemize}
\end{frame}


% Why Machine Learning? (Ctd.)
\begin{frame}{Why Machine Learning? (Ctd.)}{}
	\textit{`I keep saying the sexy job in the next ten years will be \textbf{statisticians} and \textbf{machine learners}.
		People think I’m joking, but who would’ve guessed that computer engineers would’ve been the sexy job of the
		1990s? The ability to take data - to be able to understand it, to process it, to extract value from it, to visualize it,
		to communicate it - that’s going to be a hugely important skill in the next decades.' \\
		\hfill\textbf{-- Hal Varian}, Chief Economist at Google, 2009}
\end{frame}


% Definition of Machine Learning
\begin{frame}{Definition of Machine Learning}{}
	\begin{itemize}
		\item \textit{`[Machine Learning is the] field of study that gives computers the ability
			to learn without being explicitly programmed.' \\
			\hfill\textbf{-- Arthur Samuel}, 1959}
		\vspace*{5mm}
		\item \textit{`A computer program is said to learn from experience $E$ with respect to some class of 
			tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with
			experience $E$.' \\
			\hfill\textbf{-- Tom Mitchell}, 1997}
	\end{itemize}
\end{frame}


% A more abstract Definition
\begin{frame}{A more abstract Definition}{}
	\begin{itemize}
		\item Our task is to learn a mapping from input to output:
		\begin{equation*}
			h : \mathcal{I} \mapsto \mathcal{O}
		\end{equation*}
		\item Put differently, we want to predict the output from the input:
		\begin{equation*}
			y = h(\bm{x}; \bm{\theta}) \qquad\text{also:}\quad y = h_{\bm{\theta}}(\bm{x})
		\end{equation*}
		\begin{boxBlueNoFrame}
			\item $\bm{x} \in \mathcal{I}$ (Input)
			\item $y \in \mathcal{O}$ (Output)
			\item $\bm{\theta} \in \bm{\Theta}$ (Parameters: What needs to be `learned')
		\end{boxBlueNoFrame}
	\end{itemize}
\end{frame}


% Section: Problem Types in Machine Learning
%______________________________________________________________________
\section{Problem Types in Machine Learning}
\makedivider{Problem Types in Machine Learning}

% Subsection: Type of Training Information
% --------------------------------------------------------------------------------------------------------
\subsection{Type of Training Information}

% Type of Training Information
\begin{frame}{Type of Training Information}{}
	\begin{itemize}
		\item \highlight{Supervised learning}
		\begin{itemize}
			\item `Teacher' provides \textbf{gold labels}
			\item E.\,g. neural networks, decision trees, linear regression
		\end{itemize}
		\item \highlight{Unsupervised learning}
		\begin{itemize}
			\item Labels are \textbf{not} known during training
			\item E.\,g. clustering, density estimation, association rule mining
		\end{itemize}
		\item \highlight{Reinforcement learning}
		\begin{itemize}
			\item Environment provides rewards for actions but correct action is unknown
			\item E.\,g. policy-iteration, Q-learning, SARSA
		\end{itemize}
		\item \highlight{Semi-supervised learning} (Instances partly labeled)
	\end{itemize}
\end{frame}


% Type of Training Information (Ctd.)
\begin{frame}{Type of Training Information (Ctd.)}{}
	\input{01_intro_ml/01_tikz/type_of_training_information}
\end{frame}


% Supervised Learning
\begin{frame}{Supervised Learning}{}
	\divideTwo{0.49}{
		\begin{itemize}
			\small
			\item A single row is called \highlight{example}
			\item An example without class label is called \highlight{instance}
			\item \highlight{Predictors:}
			\begin{itemize}
				\scriptsize
				\item Outlook $\in \{sunny, overcast, rainy\}$
				\item Temperature $\in \{hot, mild, cool\}$
				\item Humidity $\in \{high, normal\}$
				\item Wind $\in \{weak, strong\}$
			\end{itemize}
			\item \highlight{Label:}
			\begin{itemize}
				\scriptsize
				\item PlayGolf $\in \{yes, no\}$
				\item Given a new instance we want to predict the label
			\end{itemize}
			\item \textbf{Label for the new instance???}
		\end{itemize}
	}{0.49}{
		\vspace*{2mm}
		\input{01_intro_ml/03_tbl/example_data_set}
	}
\end{frame}


% Supervised Learning: General Approach
\begin{frame}{Supervised Learning: General Approach}{}
	\vspace*{-5mm}
	\input{01_intro_ml/01_tikz/supervised_learning_general_approach}
\end{frame}


% Unsupervised Learning
\begin{frame}{Unsupervised Learning}{}
	\divideTwo{0.49}{
		\vspace*{5mm}
		\input{01_intro_ml/01_tikz/unsupervised_learning}
	}{0.49}{
		\begin{itemize}
			\item There are \textbf{no} labels
			\item Try to find regularities in the data
			\item Examples for unsupervised learning:
			\begin{itemize}
				\item \highlight{Clustering}
				\item \highlight{Density estimation}
				\item \highlight{Dimensionality reduction}
			\end{itemize}
		\end{itemize}
	}
\end{frame}


% Subsection: Availability of Training Examples
% --------------------------------------------------------------------------------------------------------
\subsection{Availability of Training Examples}

% Availability of Training Examples
\begin{frame}{Availability of Training Examples}{}
	\begin{itemize}
		\item \highlight{Batch Learning}
		\begin{itemize}
			\item The learner is provided with a fixed set of training examples
			\item See weather data set
			\item E.\,g. neural networks, decision trees
		\end{itemize}
		\item \highlight{Incremental/Online Learning}
		\begin{itemize}
			\item Constant stream of training examples
			\item The model is updated as new training examples arrive
			\item E.\,g. k-nearest-neighbors
		\end{itemize}
		\item Active Learning (\textit{not covered})
	\end{itemize}
\end{frame}


% Subsection: Type of Target Variable
% --------------------------------------------------------------------------------------------------------
\subsection{Type of Target Variable}

% Type of Target Variable: Regression
\begin{frame}{Type of Target Variable: Regression}{}
	\divideTwo{0.49}{
		\highlight{Regression}
		\begin{itemize}
			\item Learn a mapping into a continuous space
			\begin{itemize}
				\item $\mathcal{O} = \mathbb{R}$
				\item $\mathcal{O} = \mathbb{R}^3$
			\end{itemize}
			\item E.\,g. curve fitting, financial analysis, housing prices, ...
		\end{itemize}
	}{0.49}{
		\includegraphics[scale=0.5]{01_intro_ml/02_img/regression_example}
	}
\end{frame}


% Type of Target Variable: Classification
\begin{frame}{Type of Target Variable: Classification}{}
	\divideTwo{0.49}{
		\includegraphics[scale=0.25]{01_intro_ml/02_img/classification_example}
	}{0.49}{
		\highlight{Classification}
		\begin{itemize}
			\item Learn a mapping into a discrete space, e.\,g.
			\begin{itemize}
				\item $\mathcal{O} = \{0, 1\}$ (binary classification)
				\item $\mathcal{O} = \{0, 1, 2, 3, ...\}$
				\item $\mathcal{O} = \{verb, noun, adverb, ...\}$
			\end{itemize}
			\item Examples:
			\begin{itemize}
				\item Spam / no spam
				\item Digit recognition
				\item Part of speech tagging
			\end{itemize}
		\end{itemize}
	}
\end{frame}


% Section: Key Challenges in Machine Learning
%______________________________________________________________________
\section{Key Challenges in Machine Learning}
\makedivider{Key Challenges in Machine Learning}

\begin{frame}{}{}

\end{frame}


% Section: Lecture Overview
%______________________________________________________________________
\section{Lecture Overview}
\makedivider{Lecture Overview}

\makeoverview{1}


% Section: Wrap-Up
%______________________________________________________________________
\section{Wrap-Up}

% Subsection: Summary
% --------------------------------------------------------------------------------------------------------
\subsection{Summary}

% Summary
\begin{frame}{Summary}{}

\end{frame}


% Subsection: Self-Test Questions
% --------------------------------------------------------------------------------------------------------
\subsection{Self-Test Questions}

% Self-Test Questions
\begin{frame}{Self-Test Questions}{}

\end{frame}

% Subsection: Recommended Literature and further Reading
% --------------------------------------------------------------------------------------------------------
\subsection{Recommended Literature and further Reading}

% Literature
%______________________________________________________________________
\begin{frame}{Recommended Literature and further Reading}{}
	\footnotesize
	\begin{thebibliography}{2}
		\literature{book}{Mitchell.1997}{[1] Machine Learning}
			{Tom Mitchell. McGraw-Hill Science. 1997.}{$\rightarrow$ See chapter 1 (Introduction)}
	\end{thebibliography}
\end{frame}


% Thank you
%______________________________________________________________________
\makethanks


%\section{Notation}
%
%% Notation
%\begin{frame}{Notation}
%	\begin{itemize}
%		\item Mathematical notation:
%		\begin{itemize}
%			\item Scalars: Standard letters, e.\,g. $h$, $t$, ...
%			\item Vectors: Bold-faced letters, e.\,g. $\bm{x}$, $\bm{\theta}$, ...
%			\item Matrices: Bold-faced capital letters, e.\,g. $\bm{W}$, $\bm{\Phi}$, ...
%		\end{itemize}
%		\item Symbols:
%	\end{itemize}
%
%	\input{04_ml_introduction/03_tbl/notation}
%\end{frame}


\end{document}